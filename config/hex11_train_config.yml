### hyperparameters ###

replaybuf_size: 100000  # per worker
replaybuf_resample: 10
replaybuf_oversampling: 1.0 # 1.0 = 100%

lr_initial: 1.0e-1
lr_decay_steps: 50000
lr_decay: 0.3
momentum: 0.9
l2_regularization: 1.e-4
lr_decay_epochs: 391 # 1 epoch = 128 batches

total_steps: 1000000  # Reduced total steps for quicker training

# Adjusted batch size to potentially improve training speed
batch_size: 128  

#epochs
total_epochs: 50  # Reduced total epochs to limit training time

# c_PUCT
exploration_coef: 0.5

# tau
exploration_temperature: 1.0

exploration_depth: 15
exploration_noise_alpha: 0.03
exploration_noise_scale: 0.25

# network architecture
num_blocks: 6
base_chans: 64

# Reduced simulations for faster evaluation during training
simulations: 400

# MCTS simulation and evaluation batching
search_batch_size: 10

# CPU Core Architecture
num_player_workers: 8
num_dataloader_workers: 8  # Reduced to optimize memory usage

### runtime configuration (no hyperparameters) ###

log_interval: 500
model_checkpoint_interval: 10000      # Keep as is for model checkpoints
replaybuf_checkpoint_interval: 50000   # Keep as is for replay buffer checkpoints

seed: 0xBAD5EED5
device: 'auto'

game: 'azalea.game.hex.HexGame'
network: 'HexNetwork'
board_size: 11